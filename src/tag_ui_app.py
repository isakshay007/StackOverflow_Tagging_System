import streamlit as st
import joblib
import pickle
import numpy as np
import torch
import types
from torch import nn
from transformers import DistilBertTokenizer, DistilBertModel
from huggingface_hub import hf_hub_download
from hmm import HMM_Tagger

# ğŸ©¹ Fix for PyTorch+Streamlit reload bug
if not hasattr(torch.classes, '__path__'):
    torch.classes.__path__ = types.SimpleNamespace(_path=[])

# ========= MODEL CLASS =========
class MiniTagTransformer(nn.Module):
    def __init__(self, num_tags):
        super().__init__()
        self.bert = DistilBertModel.from_pretrained("distilbert-base-uncased")
        self.classifier = nn.Linear(self.bert.config.hidden_size, num_tags)

    def forward(self, input_ids, attention_mask):
        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)
        cls_output = outputs.last_hidden_state[:, 0, :]
        return self.classifier(cls_output)

# ========= LOADERS =========
@st.cache_resource(show_spinner=False)
def load_ml():
    model = joblib.load("models/tagging_model.pkl")
    mlb = joblib.load("models/tagging_mlb.pkl")
    return model, mlb

@st.cache_resource(show_spinner=False)
def load_hmm():
    model = HMM_Tagger()
    model.load_model("models/hmm_model3.pkl")
    return model

@st.cache_resource(show_spinner=False)
def load_bert():
    model_path = hf_hub_download(repo_id="iakshay777/stackoverflow-tag-model", filename="trained_model.pt", repo_type="model")
    mlb_path = hf_hub_download(repo_id="iakshay777/stackoverflow-tag-model", filename="mlb.pkl", repo_type="model")
    with open(mlb_path, "rb") as f:
        mlb = pickle.load(f)
    tokenizer = DistilBertTokenizer.from_pretrained("distilbert-base-uncased")
    model = MiniTagTransformer(num_tags=len(mlb.classes_))
    model.load_state_dict(torch.load(model_path, map_location=torch.device("cpu")))
    model.eval()
    return model, mlb, tokenizer

# ========= PREDICTION FUNCTIONS =========
def predict_ml(model, mlb, text, threshold=0.08):
    probs = model.predict_proba([text])[0]
    sorted_probs = sorted(zip(mlb.classes_, probs), key=lambda x: x[1], reverse=True)
    tags = [tag for tag, score in sorted_probs if score >= threshold]
    return tags, sorted_probs

def predict_hmm(model, title, description):
    text = f"{title.strip()} {description.strip()}"
    return model.predict(text)  # already returns top 5

def predict_bert(text, model, tokenizer, mlb, threshold=0.05, show_top_k=5, fallback=True):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding="max_length", max_length=128)
    with torch.no_grad():
        logits = model(inputs["input_ids"], inputs["attention_mask"])
        probs = torch.sigmoid(logits).squeeze().cpu().numpy()
    top_probs = sorted(enumerate(probs), key=lambda x: x[1], reverse=True)[:show_top_k]
    indices = np.where(probs >= threshold)[0]
    tags = [mlb.classes_[i] for i in indices]
    if fallback and not tags:
        tags = [mlb.classes_[i] for i, _ in top_probs]
    return tags, [(mlb.classes_[i], p) for i, p in top_probs]

# ========= STREAMLIT UI =========
st.set_page_config(page_title="StackOverflow Tag Generator", layout="wide")
st.title("ğŸš€ StackOverflow Tag Generator")

# Track model selection
if "model_selected" not in st.session_state:
    st.session_state.model_selected = None

# Model Selection Dropdown
model_choice = st.selectbox("ğŸ“Š Choose a Tag Prediction Model", [
    "Logistic Regression (ML)",
    "Hidden Markov Model (HMM)",
    "DistilBERT Transformer"
], index=0)

if st.button("âœ… Select Model"):
    st.session_state.model_selected = model_choice
    if model_choice == "Logistic Regression (ML)":
        st.session_state.ml_model, st.session_state.mlb_ml = load_ml()
    elif model_choice == "Hidden Markov Model (HMM)":
        st.session_state.hmm_model = load_hmm()
    elif model_choice == "DistilBERT Transformer":
        st.session_state.bert_model, st.session_state.mlb_bert, st.session_state.tokenizer = load_bert()

# Input Fields
if st.session_state.model_selected:
    st.subheader(f"ğŸ“ Enter Question for {st.session_state.model_selected}")
    title = st.text_input("ğŸ“Œ Title", placeholder="e.g., How to resolve CORS error in JavaScript?")
    description = st.text_area("ğŸ§ Description", height=200, placeholder="Include details, errors, etc.")

    if st.button("ğŸ” Generate Tags"):
        if not title.strip() and not description.strip():
            st.warning("Please provide at least a title or description.")
        else:
            with st.spinner("Generating tags..."):

                if st.session_state.model_selected == "Logistic Regression (ML)":
                    text = f"{title.strip()} {description.strip()}"
                    tags, scores = predict_ml(st.session_state.ml_model, st.session_state.mlb_ml, text)
                    st.subheader("ğŸ¯ Tags")
                    st.write(", ".join(tags[:5]) if tags else "No tags found.")
                    st.subheader("ğŸ“Š Top Probabilities")
                    for tag, score in scores[:5]:
                        st.write(f"**{tag}**: {score:.3f}")

                elif st.session_state.model_selected == "Hidden Markov Model (HMM)":
                    tags = predict_hmm(st.session_state.hmm_model, title, description)
                    print("DEBUG | HMM Predicted Tags:", tags)
                    st.subheader("ğŸ¯ Tags")
                    st.write(", ".join(tags) if tags else "No tags found.")

                elif st.session_state.model_selected == "DistilBERT Transformer":
                    text = f"{title.strip()} {description.strip()}"
                    tags, scores = predict_bert(
                        text,
                        st.session_state.bert_model,
                        st.session_state.tokenizer,
                        st.session_state.mlb_bert
                    )
                    st.subheader("ğŸ¯ Tags")
                    st.write(", ".join(tags[:5]) if tags else "No tags found.")
                    st.subheader("ğŸ“Š Top Scores")
                    for tag, prob in scores[:5]:
                        st.write(f"**{tag}**: {prob:.3f}")

# Footer
st.markdown("---")
st.caption("Built with â¤ï¸ using Streamlit, Transformers, and scikit-learn")
